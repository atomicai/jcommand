{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib, os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jc.speech import tool\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm\n",
    "import itertools\n",
    "from more_itertools import chunked\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\justatom\\\\Project\\\\jcommand'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(str(pathlib.Path(os.getcwd()) / \"silero_encoder_v6.pth\"), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tool.Decoder(labels=model.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset speech_commands (C:\\Users\\justatom\\.cache\\huggingface\\datasets\\speech_commands\\v0.02\\0.2.0\\ba3d9a6cf49aa1313c51abe16b59203451482ccb9fee6d23c94fecabf3e206da)\n",
      "100%|██████████| 3/3 [00:00<00:00, 10.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_commands = datasets.load_dataset(\"speech_commands\", \"v0.02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    (\"yes\", 0), \n",
    "    (\"no\", 1),\n",
    "    (\"up\",  2),\n",
    "    (\"down\", 3), \n",
    "    (\"left\", 4),\n",
    "    (\"right\", 5),\n",
    "    (\"on\", 6),\n",
    "    (\"off\", 7),\n",
    "    (\"stop\", 8),\n",
    "    (\"go\", 9),\n",
    "    (\"zero\", 10),\n",
    "    (\"one\", 11),\n",
    "    (\"two\", 12),\n",
    "    (\"three\", 13),\n",
    "    (\"four\", 14),\n",
    "    (\"five\", 15), \n",
    "    (\"six\", 16),\n",
    "    (\"seven\", 17),\n",
    "    (\"eight\", 18),\n",
    "    (\"nine\", 19),\n",
    "    (\"bed\", 20),\n",
    "    (\"bird\", 21),\n",
    "    (\"cat\", 22),\n",
    "    (\"dog\", 23),\n",
    "    (\"happy\", 24),\n",
    "    (\"house\", 25),\n",
    "    (\"marvin\", 26),\n",
    "    (\"sheila\", 27),\n",
    "    (\"tree\", 28),\n",
    "    (\"wow\", 29),\n",
    "    (\"backward\", 30),\n",
    "    (\"forward\", 31),\n",
    "    (\"follow\", 32),\n",
    "    (\"learn\", 33),\n",
    "    (\"visual\", 33)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = { v: w for w, v in commands }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_text(batch, encoder, decoder, device = None, sr: int = 16_000, mapping: Dict = None):\n",
    "    if device is None:\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    labels = [_[\"label\"] for _ in batch]\n",
    "    audio  = [_[\"audio\"] for _ in batch]\n",
    "    noisy_array = [_[\"array\"] for _ in audio]\n",
    "    # denoisy_array = [nr.reduce_noise(y=a, sr=16_000) for a in noisy_array]\n",
    "    x = tool.prepare_model_input(\n",
    "        [torch.from_numpy(ex) for ex in noisy_array],\n",
    "        device=device\n",
    "    )\n",
    "    output = model(x)\n",
    "    assert len(output) == len(noisy_array)\n",
    "    response = []\n",
    "    for i, (example, label) in enumerate(zip(output, labels)):\n",
    "        preds = decoder(example.cpu())\n",
    "        response.append(\n",
    "            {\n",
    "                \"preds\": preds,\n",
    "                \"labels\": mapping.get(label, \"unknown\"),\n",
    "                \"array\": noisy_array[i]\n",
    "            }\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in itertools.islice(enumerate(tqdm(chunked(dataset_commands[\"train\"], n=batch_size))), num_samples):\n",
    "    response = wav_to_text(batch=batch, encoder=model, decoder=decoder, device=\"cpu\", mapping=mapping)\n",
    "    monitor.extend(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'preds': 'by cor',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00012207,\n",
       "         -0.00015259, -0.00012207])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.00024414,  0.00106812,  0.00115967, ..., -0.0005188 ,\n",
       "         -0.00012207, -0.00042725])},\n",
       " {'preds': 'big w',\n",
       "  'labels': 'backward',\n",
       "  'array': array([0.00027466, 0.00027466, 0.00091553, ..., 0.00567627, 0.00708008,\n",
       "         0.00860596])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.00018311,  0.00048828,  0.00067139, ..., -0.00018311,\n",
       "         -0.00042725, -0.00033569])},\n",
       " {'preds': 'm',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.01748657,  0.02087402,  0.01416016, ..., -0.00268555,\n",
       "         -0.00338745, -0.00393677])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([-9.15527344e-05, -1.52587891e-04, -2.44140625e-04, ...,\n",
       "         -2.13623047e-04,  3.05175781e-05, -1.52587891e-04])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([0.        , 0.        , 0.        , ..., 0.00033569, 0.00027466,\n",
       "         0.00021362])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.00000000e+00,  3.05175781e-05,  0.00000000e+00, ...,\n",
       "         -2.15454102e-02, -2.25830078e-02, -2.26440430e-02])},\n",
       " {'preds': 'that would',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 0.42510986,  0.52682495,  0.58596802, ..., -0.43695068,\n",
       "         -0.48336792, -0.46902466])},\n",
       " {'preds': 'backward',\n",
       "  'labels': 'backward',\n",
       "  'array': array([ 9.15527344e-05,  3.05175781e-04,  2.44140625e-04, ...,\n",
       "         -3.66210938e-04, -3.35693359e-04, -2.74658203e-04])}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(monitor[random_index][\"array\"], samplerate=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9766729549fed04f058127e4e6ade96fe848d91511c2be514239fb19d5ebb34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
